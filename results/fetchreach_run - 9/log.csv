time/steps,time/epochs,time/steps_per_second,time/dataset,time/preprocess,time/train_step,train/env_steps,eval/success,eval/reward,eval/length,eval/is_success,eval/reward_std,step,train/reward,train/length,train/num_ep,train/q_loss,train/target_q,train/actor_loss,train/entropy,train/alpha_loss,train/alpha
10000,0,348.06993690382615,0.0003361701965332031,0.0017237663269042969,0.03721904754638672,9501.5,0.0,-14.399870525889762,50.0,0.0,3.432221675561658,10000,-15.774326751013135,50.0,190.5,0.3798104226589203,-0.4034944623708725,0.09527531638741493,-0.6018872857093811,0.33975961804389954,0.0999550111591816
15000,0,32.27545984079548,0.0003840923309326172,0.0009369850158691406,0.034240007400512695,14501.5,0.026,-7.531355870377166,50.0,0.1,1.496038465954597,15000,-8.537172945427423,50.0,290.5,0.20470610934495925,-2.330323446750641,2.3744389820098877,1.7394948946237565,0.18946576209366323,0.03293656378798187
20000,0,32.28934651122539,0.0003647804260253906,0.0010170936584472656,0.03233003616333008,19501.5,0.003,-19.362884167008637,50.0,0.05,3.1031329034963697,20000,-17.579331945595236,50.0,390.5,0.8633011094629764,-4.832605422973633,4.940424746513367,-4.719775899410248,-0.013522812702532975,0.018996557185426356
25000,0,32.72703878711805,0.00037789344787597656,0.0010008811950683594,0.04058432579040527,24501.5,0.0,-32.88790641137954,50.0,0.0,3.2119036961189273,25000,-28.180429374203676,50.0,490.5,2.6694013254642486,-6.5033278632164,6.727555373668671,-5.18704327347409,-0.04018001724220812,0.03467858239263296
